\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{lmodern}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{color}%para poder definir, utilizar colores en fuente, fondo...etc
\setcounter{page}{0}%Para que la página de título no se tenga en cuenta
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{eurosym}
\setcounter{secnumdepth}{5} %Para subsubsusbsection, se debe poner paragraph.

\usepackage{listings}%Entornos de código
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

%\lstset{frame=tb,
%  language=Java,
%  aboveskip=3mm,
%  belowskip=3mm,
%  showstringspaces=false,
%  columns=flexible,
%  basicstyle={\small\ttfamily},
%  numberstyle=\tiny\color{gray},
%  keywordstyle=\color{blue},
%  commentstyle=\color{dkgreen},
%  stringstyle=\color{mauve},
%  breaklines=true,
%  breakatwhitespace=true
%  tabsize=2
%}

\lstset{frame=tb,
  language=Java,% Set your language (you can change the language for each code-block optionally)
  basicstyle=\footnotesize\ttfamily,
  numbers=left,
  morekeywords={end},
  aboveskip=3mm,
  belowskip=3mm,
  backgroundcolor=\color{white},
  frame=single,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{mauve},
  commentstyle=\color{mygreen},
  stringstyle=\color{blue},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2
}

\setlength{\parskip}{2mm}%Separación entre párrafos.

%kuggle.com  


\author{Jose Ignacio Sánchez\\Josu Rodríguez}
\title{\begin{center}\textbf{\Huge{Minería de datos} Práctica 1:Clustering knn-means}
%\begin{center}\includegraphics[scale=0.5]{./img/SVM-classifiers.jpg} 
%\footnote{Imagen
%extraida de \url{http://www.thebookmyproject.com/cars/intrusion-detection-technique-using-k-means-fuzzy-neural-network-svm-classifiers/intrusion-detection-technique-by-using-k-means-fuzzy-neural-network-and-svm-classifiers/}}
%\end{center} 
\end{center}}
\date{\today}


\newtheorem{defi}{(\it Definición)}[section]%Para obtener las definiciones enumeradas, con la sección que las contiene
\newtheorem{teorema}{(\it Teorema)}[section]%Para obtener los teoremas enumeradas, con la sección que las contiene

\makeindex

\renewcommand{\tablename}{\textbf{Tabla}}

\begin{document}

\maketitle

\thispagestyle{empty}%para evitar enumeración de la página de la portada y del índice

\newpage

%Tabla de contenido
\renewcommand\contentsname{\centering ÍNDICE DE CONTENIDO}
\tableofcontents%índice
\thispagestyle{empty}
\newpage

%Lista de tablas
\renewcommand{\listtablename}{\centering ÍNDICE DE TABLAS} %Para cambiar el índice de las tablas
\listoftables
\thispagestyle{empty}
\newpage

%lista de figuras 
\renewcommand\listfigurename{\centering ÍNDICE DE FIGURAS}
\thispagestyle{empty}
\listoffigures
\clearpage

\setcounter{page}{1}%Para reinizar el contador de páginas en la página deseada

\section{Introducción}

El objetivo principal de esta práctica es obtener la capacidad de formular un
algoritmo de aprendizaje automático de clasificación \textbf{\textit{No-Supervisada}}. 
Por otra parte, se trabajarán la capacidad de sintetizar uns técnica de aprendizaje automático
no-supervisado, conocer su coste computacional así como sus limitaciones de representación
y de inteligibilidad \par

%\begin{defi}
%	Esto es una definición o teorema.
%\end{defi}

\section{Recursos}
\begin{itemize}
	\item PC con aplicación Weka.
	\item Bibliografía.
	\item Librerías de  Weka.
	\item Manual de Weka.
	\item Guía de la práctica.
	\item Ficheros para los datos de la
	práctica:
	\textcolor{green}{food.arff},
	\textcolor{green}{colon.arff}.
	\item Otros ficheros que no están en formato \textit{.arff}:
		\begin{itemize}
			\item En formato \textit{.txt}: \textcolor{green}{ClusterData.atributos.txt} (este fichero si tiene la clase asociada para 
			evaluar la calidad del \textit{clustering} en \textcolor{green}{ClusterData.clase.txt}).
			\item E formato \textit{.csv} \textcolor{green}{bank-data.csv}clustering
		\end{itemize}
\end{itemize}

\section{Clasificación \textbf{NO-supervisada} o \textit{Clustering}}

\begin{defi}
	Técnicas de aprendizaje donde no hay un conocimiento a priori, donde agrupa las instancias sin atributos dependientes pre-especificados.Los algoritmos "clustering" son un método común de aprendizaje no supervisado.
\end{defi}

\subsection{Clustering \textit{\textbf{k-means}}}


\section{Diseño}
 
 Estructuramos la ejecución del algoritmo en fases como se puede ver en la figura \ref{fig:dependencias} , las cuales se detallan a continuación.\\
 
\subsection*{Primera fase: carga de datos y configuración}
 
 Inicialmente se carga la configuración
 establecida por el usuario en el fichero \textbf{kmeans.conf}, es decir: path
 del fichero y su formato, tipo de inicialización para el \textit{codebook}, número de clusters, distancia a
 utilizar, número de clústers deseados, elección manual o automática sobre la
 normalización y diversas opciones más, especificando datos sobre el fichero que
 se utilizará para las instancias.

\subsection*{Segunda fase: Preproceso de datos}

En el preproceso de datos se normalizará o no, dependiendo del parámetro
indicado por el usuario. Si el parámetro es 0 no se normalizará, si es 1 se
normaliza y si es 2 se hará uso del método experimental para decidir la
idoneidad de la normalización.

\subsection*{Tercera Fase: Algoritmo K-means}

En esta fase se implementa el algoritmo \textbf{K-means}.
\begin{enumerate}
	\item En primer lugar inicia los \textit{centroides} con el criterio establecido por el usuario, o la matriz de bits de pertenencias.
	\item Recorre las instancias del conjunto y calcula la distancia a cada uno de los \textit{codeword} actualizando la matriz de bits de pertenencia,el valor 		del bit es uno si es el centroide más cercano a la instancia.
	\item Se calcula de nuevo el vector promedio para cada cluster.
	\item Iterar los pasos dos y tres hasta converger.
\end{enumerate}

\subsection*{Cuarta Fase: Evaluación}

En esta fase se tratará de automatizar la evaluación del algoritmo frente a los datos obtenidos con distintas ejecuciones, variando los parámetros o incluso con  
los resultados obtenidos con el modelo de \textbf{K-means} que ya implementa el API de \textbf{weka}.

\subsection*{Dependencias}
 %mapa de diseño donde se muestran las dependencias y se documentan las rutinas.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{./img/dependenciasKmeans.pdf}%crear esquema para incluirlo
	\caption[Esquema de dependencias del sistema]{Dependencias del sistema}
	\label{fig:dependencias}
\end{figure}

%\footnotetext{Imagen obtenida de:
%\href{http://stackoverflow.com/questions/6160495/support-vector-machines-a-simple-explanation}{http://stackoverflow.com/questions/6160495/support-vector-machines-a-simple-explanation}.}

%\footnotetext{Imagen obtenida de:
%\href{http://en.wikipedia.org/wiki/File:Svm\_max\_sep\_hyperplane\_with\_margin.png}{\nolinkurl{http://en.wikipedia.org/wiki/File:Svm\_max\_sep\_hyperplane\_with\_margin.png}}.}

%\begin{equation}
%	min\frac{1}{2}||w||^{2}
%	\label{eq:pl}
%\end{equation}

\subsection{Algoritmo en pseudocódigo}

\begin{lstlisting}[mathescape=true]
Let k be the number of clusters to partition the data set
Let $X = {x_{1},x_{2}, ..., x_{n}}$ be the data set to be analyzed
Let $M = {m_{1}, m_{2}, ..., m_{k}}$ be the code-book associated to the clusters
Let $dist(a, b)$ be the desired distance metric
Let $B = {B_{11}, B_{12}, ..., B_{nk}}$ be the temporary pertenece bit matrix

Ensure: $C = {C_{1}, C_{2}, ..., C_{k}}$ set of clusterized instances

Begin:

	//randomly initialize the first centroids
	for each $m_{j}$
		$m_{j}$ = $randomsample(X)$
	end
	
	//assign dataset instances to each cluster generated by the centroids
	for each $x_{n}$
		$B_{nj} = 1$ si argmin $dist(x_{n},m_{j}) = m_{j}$ \foreach $m_{j}$ si no $B_{nj} = 0$ 
	end
		
	for each $B_{nj}$
		if $B_{nj} == 1$
			$C_{j}.add(x_{i})$ 
		end
	end
	
	//iterate the algorithm generatin new centroids based on previously clusterized instances until there are no changes between iterations
	while changes in M do
		for each $m_{j}$
			$m_{j}new = calculatecentroid(C_{j})$
			if $m_{j}new == m_{j}$
				changes = false
			else
				changes = true
			end
			$m_{j} = m_{j}new$	
		end
		
		for each $x_{n}$
			$B_{nj} = 1$ if $argmindist(x_{n},m_{j}) = m_{j}$ \foreach $m_{j}$ else $B_{nj} = 0$
		end
		
		for each $B_{nj}$
			if $B_{nj} == 1$
				$C_{j}.add(x_{i}) $
			end
		end
	end
	
	return $C = {C_{1}, C_{2}, ..., C_{k}}$
end

\end{lstlisting}

\section{Implementación}

\subsection{Análisis del conjunto de datos para decidir la conveniencia de la normalización}
Debido a las dudas surgidas en torno a la normalización de los atributos y su conveniencia, consideramos adecuado para la tarea tratar de buscar algún método que fuese
en alguna manera indicador de la utilidad de la normalización.

En un principio nuestro planteamiento se basaba en utilizar la media de la desviación típica de los valores de cada atributo con el objeto de poder analizar los rangos 
de las diferencias entre valores de cada atributo. Sin embargo la media por su cuenta no nos es útil, ya que por ejemplo, si la media es alta pero la desviación es baja, 
en realidad, puede no haber mucha variación en los rangos. Esto nos llevó a
hallar el Coeficiente de Variación\\

\begin{equation}
C_{V}=\frac{\sigma}{\bar{x}}
 \end{equation}\\

De esta forma logramos un indicador más preciso sobre el rango que buscamos ya que nos indica la proporción de la variabilidad de las desviaciones, en lugar de la mera 
cantidad de desviación.

La motivación de este análisis viene dada más por el interés de hallar una forma de conocer la utilidad que pueda tener la normalización en un conjunto de datos, ya que
 objetivamente, el beneficio principal que puede tener es que si no afecta demasiado al resultado final, nos puede interesar más tener los atributos en su rango numérico inicial (p.ej.: es más visual ver un gráfico con edades entre 0 y 100 que entre 0 y 1).

Por otra parte, hemos tratado de hallar una cifra del Coeficiente de Variación que esté comunmente aceptada como baja, pero no hemos encontrado ninguna fuente fidedigna 
para ello. Por lo tanto, hemos decidido establecer una cifra pequeña (0,1) teniendo en cuenta que ante la posibilidad de que haya rangos muy variados, puede ser más 
conveniente normalizar.

Huelga decir que este método y sus resultados son experimentales, pese a tener cierta base empírica carecemos de la certeza sobre su eficacia, siendo nuestro objetivo 
principal investigar respecto a la normalización en lugar de simplemente aplicarla por estar aceptada como conveniente. 


\subsection{Problemas encontrados y soluciones adoptadas}


\subsubsection{Problema con la normalización de los atributos}
En un comienzo, para normalizar, nuestra intención era aplicar la función Z-Score sobre los atributos de las diferentes instancias. Sin embargo, de esta forma se 
obtenían resultados fuera del rango de [-1, 1], que es incorrecto para esta normalización. No se consiguió localizar el error, desconociendo si se trataba de una
 formulación incorrecta o un bug de programación. En lugar de ello se ha realizado una proyección lineal al intervalo [0,1] y de esta forma se ha conseguido 
 unificar los atributos en el mismo intervalo.

\subsubsection{Problema de generación de excesivas instancias}
Una vez estructurado todo el código y con todos los módulos programados, nos encontramos con el problema de que durante la ejecución, 
se generaban demasiadas instancias. Esto se debía a que en cada iteración del algoritmo, los clusters no eran reseteados correctamente, y cada vez que se añadía 
una nueva instancia en lugar de eliminar la que estaba presente en su lugar, desplazaba esta última y se insertaba en su posición. Para corregir esto sencillamente
se modificó la función de añadir instancias para que esta sobreescribiese la presente, y además, se resetean los clusters en cada iteración.

\subsubsection{Instancias repetidas en los gráficos}
Al igual que en el anterior problema, nos encontramos con que a la hora de graficar, se marcaban más instancias de las que realmente había. La solución también pasó por 
realizar un reinicio de la matriz de bits en cada iteración del algoritmo.

\subsubsection{Ausencia de representación para el cluster 0}
Una vez incorporado el código necesario para la generación de gráficos su funcionamiento era correcto, pero no mostraba los datos del cluster 0. El problema radicaba
 en que a la hora de tratar la matriz de bits de pertenencia, el primer caso se trataba fuera de un bucle y por ello no se hacían las actualizaciones correctas. Una 
 vez corregido esto el gráfico se crea correctamente.

\subsubsection{Análisis de condición de parada del algoritmo incorrecta}
En las últimas fases de desarrollo del software, cuando decidimos volver a
hablitar la opción de que el algoritmo itere hasta encontrar la solución óptima
local (dada la inicialización), la comparación de los nuevos codewords con los
anteriores daba problemas. Haciendo uso de la herramienta de debug descubrimos
que el origen de esto era la comparación de todos los clusters entre sí, en
lugar de cada uno con su par.

\section{Validación del \textit{software}}

\subsection{Diseño del banco de pruebas}

\section{Análisis de resultados}

\subsection{Modificando inicializaciones}

\subsection{Modificando distancia Minkowski}

\subsection{Criterios de convergencia}

\subsubsection{Número fijo de iteraciones}

\subsubsection{Disimilitud entre \textit{codebooks}}

\subsection{Distintas métricas}

\subsubsection{Manhattan}

\subsubsection{Euclídea}

\subsubsection{Minkowski}

\section{Clasificación supervisada respecto de }

%\section{Preproceso de los datos}
%
%\subsubsection{Randomize}
%
%\subsubsection{Normalize}
%
%\subsubsection{Outliers y Extreme Values}
%
%\subsubsection{Problemas al implementar el preproceso de datos}
%
%\subsection{Utils}
%
%\subsubsection{StopWatch}
%
%Esta función se encarga de indicarnos el tiempo transcurrido, en segundos,
%desde donde se instancia el objeto, hasta donde se para el
%contador\par
%
%Creemos necesario su uso, ya que nos aporta una visión objetiva del coste de tiempo computacional 
%de los distintos algoritmos implementados,como por ejemplo en el proceso de
%clasificación de las instancias sin estimar incluidas en los distintos conjuntos de
%test.
%
%\subsubsection{VerboseCutter}
%
%Esta MAE se encarga de eliminar la salida de sistema que
%imprime al hacer la evaluación el clasificador \textit{LibSVM} por defecto.\par
%
%La implementación de esta funcionalidad ha sido posible gracias a la inestimable
%ayuda por parte de otro de los grupos\footnote{David Ramírez, Begoña Carcedo,
%Andoni Martín, Marta Aguilera}.\par
%
%Eliminando la salida de sistema, podemos mostrar de forma más
%clara infomación relevante de nuestro programa, facilitando, de esta manera,
%la comprensión de los datos por parte del usuario.Además se puede seguir
%revisando dicha salida en el fichero temporal al que ha sido redireccionada.\par
%
%\paragraph{Problemas de ejecución:}
%	Al activar y desactivar esta MAE dentro de bucles anidados, no obtenemos el
%	resultado deseado, esto ocurre por falta de capacidad de respuesta por
%	capacidad de procesamiento y velocidad de escritura/lectura del disco.
%\paragraph{Solución:}
%	Aunque con desactivar la salida antes de cada evaluación es suficiente, hemos
%	sacado la llamada a la MAE fuera de los bucles(antes de los bucles se desactiva y despues de los bucles se activa la salida de sistema).
%	De esta manera hemos conseguido los resultados deseados.



\section{Conclusiones}

\subsection{Técnicas de clustering: motivación}
Tal y como se ha descrito anteriormente en este documento, el propósito de la
clasificación no supervisada es, opuestamente a la clasificación supervisada,
\textbf{descubrir} información, en lugar de predecirla. Los campos y casos a los
que es aplicable son múltiples y diversos: patrones de comportamiento en
sociología, análisis genético, reconocimiento facial, etcétera. Todo área de
conocimiento capaz de recopilar gran cantidad de datos es susceptible y puede
beneficiarse de metodologías de clustering.


\subsection{Conclusiones generales}
Debido a la modularidad del software realizado, nos ha resultado relativamente
sencillo encontrar los orígenes de los diversos errores y poder solucionarlos
así como añadir varios módulos (p. ej.:
generación de gráficos e informe) a lo largo del desarrollo, teniendo la
estructura principal del código ya hecha. Además de esto, varias de las clases
generadas son genéricas y pueden ser utilizadas en otros proyectos, como las 
funciones estadísticas de Statistics.java o la evaluación de clusters de Evaluation.java.\\

Por otra parte, la realización de esta práctica nos ha llevado a conocer en
mayor profundidad el funcionamiento de un algoritmo de cierta complejidad,
haciendo un uso mínimo de librerías externas. De no haber sido así, no se habría
descubierto el algoritmo del coeficiente Silhouette, y aún menos haberlo
implementado sin acudir a código ajeno. También cabe destacar la capacidad para
manejar diversas que se ha obtenido, así como el uso de varias funciones
estadísticas para calcular si es apto normalizar o no (experimental).

\subsection{Puntos débiles y propuestas de mejora}
Dadas la complejidad y la diversidad de funciones implementadas en el software,
ha habido ciertos aspectos en los que no ha sido posible centrarse tanto como
cabía. Podría destacarse el rendimiento del mismo, que pese a ser correcto y no
tomar demasiado tiempo con volúmenes grandes de datos, no ha sido puesto a
revisión exhaustiva por lo que podría ser mejorado.\\

Además de esto, la cantidad de métodos de evaluación que se han podido
implementar son limitados. Sin embargo no lo consideramos un punto débil
destacable, ya que el algoritmo implementado, tras su análisis y diversas
pruebas, nos ha parecido consistente y efectivo.\\

	\begin{itemize}
	
		\item Conclusiones a la vista de los resultados más relevantes.
		
	\end{itemize}

\section{Valoración subjetiva}

\begin{enumerate}

	\item ¿Has alcanzado los objetivos que se plantean? 
	
	\item ¿Te ha resultado de utilidad la tarea planteada?

	\item ¿Qué dificultades has encontrado?Valora el grado de dificultad de la tarea.

	\item  ¿Cuánto tiempo has trabajado en esta tarea? Desglosado:

		\begin{table}[H]
		\centering
		\resizebox{8cm}{!}{
						\begin{tabular}{|l|l|}
							\hline
							\multicolumn{2}{|c|}{\textbf{Coste temporal}}\\
							\hline
								Diseño de software & \\
								Implementación de software & \\
								Tiempo trabajando con Weka & \\
								Búsqueda bibliográfica & \\
								Informe & 1\\
								\hline
							\end{tabular}
						}
		\end{table}

	\item  Sugerencias para mejorar la tarea. Sugerencias para que se consiga
	despertar mayor interés y motivación en los alumnos.\par

	\item  Críticas(constructivas).

\end{enumerate} 

\newpage

\bibliographystyle{plain}
\bibliography{bibliografia}

%Ser crítico, analizar datos experemientales.Aplicar pequeños heurísticos.

\end{document} 
