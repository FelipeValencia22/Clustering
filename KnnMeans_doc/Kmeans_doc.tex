\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage[colorlinks=true, linkcolor=black, urlcolor=blue]{hyperref}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage[usenames,dvipsnames]{color}
\usepackage{lmodern}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{color}%para poder definir, utilizar colores en fuente, fondo...etc
\setcounter{page}{0}%Para que la pÃ¡gina de tÃ­tulo no se tenga en cuenta
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{eurosym}
\setcounter{secnumdepth}{5} %Para subsubsusbsection, se debe poner paragraph.

\usepackage{listings}%Entornos de cÃ³digo
\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

%\lstset{frame=tb,
%  language=Java,
%  aboveskip=3mm,
%  belowskip=3mm,
%  showstringspaces=false,
%  columns=flexible,
%  basicstyle={\small\ttfamily},
%  numberstyle=\tiny\color{gray},
%  keywordstyle=\color{blue},
%  commentstyle=\color{dkgreen},
%  stringstyle=\color{mauve},
%  breaklines=true,
%  breakatwhitespace=true
%  tabsize=2
%}

\lstset{frame=tb,
  language=Java,% Set your language (you can change the language for each code-block optionally)
  basicstyle=\footnotesize\ttfamily,
  numbers=left,
  morekeywords={end},
  aboveskip=3mm,
  belowskip=3mm,
  backgroundcolor=\color{white},
  frame=single,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{mauve},
  commentstyle=\color{mygreen},
  stringstyle=\color{blue},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2
}

\setlength{\parskip}{2mm}%SeparaciÃ³n entre pÃ¡rrafos.

%kuggle.com  


\author{Jose Ignacio SÃ¡nchez\\Josu RodrÃ­guez}
\title{\begin{center}\textbf{\Huge{MinerÃ­a de datos} PrÃ¡ctica 1:Clustering knn-means}
%\begin{center}\includegraphics[scale=0.5]{./img/SVM-classifiers.jpg} 
%\footnote{Imagen
%extraida de \url{http://www.thebookmyproject.com/cars/intrusion-detection-technique-using-k-means-fuzzy-neural-network-svm-classifiers/intrusion-detection-technique-by-using-k-means-fuzzy-neural-network-and-svm-classifiers/}}
%\end{center} 
\end{center}}
\date{\today}


\newtheorem{defi}{(\it DefiniciÃ³n)}[section]%Para obtener las definiciones enumeradas, con la secciÃ³n que las contiene
\newtheorem{teorema}{(\it Teorema)}[section]%Para obtener los teoremas enumeradas, con la secciÃ³n que las contiene

\makeindex

\renewcommand{\tablename}{\textbf{Tabla}}

\begin{document}

\maketitle

\thispagestyle{empty}%para evitar enumeraciÃ³n de la pÃ¡gina de la portada y del Ã­ndice

\newpage

%Tabla de contenido
\renewcommand\contentsname{\centering Ã�NDICE DE CONTENIDO}
\tableofcontents%Ã­ndice
\thispagestyle{empty}
\newpage

%Lista de tablas
\renewcommand{\listtablename}{\centering Ã�NDICE DE TABLAS} %Para cambiar el Ã­ndice de las tablas
\listoftables
\thispagestyle{empty}
\newpage

%lista de figuras 
\renewcommand\listfigurename{\centering Ã�NDICE DE FIGURAS}
\thispagestyle{empty}
\listoffigures
\clearpage

\setcounter{page}{1}%Para reinizar el contador de pÃ¡ginas en la pÃ¡gina deseada

\section{IntroducciÃ³n}

El objetivo principal de esta prÃ¡ctica es obtener la capacidad de formular un
algoritmo de aprendizaje automÃ¡tico de clasificaciÃ³n \textbf{\textit{No-Supervisada}}. 
Por otra parte, se trabajarÃ¡n la capacidad de sintetizar uns tÃ©cnica de aprendizaje automÃ¡tico
no-supervisado, conocer su coste computacional asÃ­ como sus limitaciones de representaciÃ³n
y de inteligibilidad \par

%\begin{defi}
%	Esto es una definiciÃ³n o teorema.
%\end{defi}

\section{Recursos}
\begin{itemize}
	\item PC con aplicaciÃ³n Weka.
	\item BibliografÃ­a.
	\item LibrerÃ­as de  Weka.
	\item Manual de Weka.
	\item GuÃ­a de la prÃ¡ctica.
	\item Ficheros para los datos de la
	prÃ¡ctica:
	\textcolor{green}{food.arff},
	\textcolor{green}{colon.arff}.
	\item Otros ficheros que no estÃ¡n en formato \textit{.arff}:
		\begin{itemize}
			\item En formato \textit{.txt}: \textcolor{green}{ClusterData.atributos.txt} (este fichero si tiene la clase asociada para 
			evaluar la calidad del \textit{clustering} en \textcolor{green}{ClusterData.clase.txt}).
			\item E formato \textit{.csv} \textcolor{green}{bank-data.csv}clustering
		\end{itemize}
\end{itemize}

\section{ClasificaciÃ³n \textbf{NO-supervisada} o \textit{Clustering}}

\begin{defi}
	Se considera \textbf{clasificaciÃ³n no-supervisada} cuando el conjunto de
	entrenamiento  no estÃ¡n las instancias etiquetadas con el valor de la clase. Es
	un experimento exploratorio, que trata de agrupar las instancias en grupos
	definidos por similitud entre las caracterÃ­sticas de las instancias que
	pertenecen al mismo grupo y disimilitud entre las que pertenecen a grupos
	distintos. Tecnicamente estos grupos son llamados \textit{Clusters}.
\end{defi}

\subsection{Clustering \textit{\textbf{k-means}}}


\section{DiseÃ±o}
 
 Estructuramos la ejecuciÃ³n del algoritmo en fases\ref{fig:dependencias} , las cuales se definen a continuaciÃ³n.\\
 
\subsection*{Primera fase: carga de datos y configuraciÃ³n}
 
 Inicialmente se encarga de cargar el fichero en una estructura de datos adecuada para el cÃ¡lculo del algoritmo.AdemÃ¡s se carga la configuraciÃ³n establecida
 por el usuario, es decir que tipo de inicializaciÃ³n para el \textit{codebook}, nÃºmero de clusters, distancia a utilizar\dots

\subsection*{Segunda fase: Preproceso de datos}

En el preproceso se normaliza el espacio, haciendo uso de la funciÃ³n estadÃ­stica zscore, es decir a cada \textit{Feature} de la instancia se le resta su media y dividiendo el resultado por la varianza de dicha \textit{Feature} se consigue que todos los valores de los atributos se encuentren dentro del intervalo [-1,1]. Con Ã©sto conseguimos evitar la mayor influencia de algunos atributos debido a que se encuentren dentro de un dominio de valores mayor. Por ejemplo si vamos a agrupar viviendas y utilizamos como caracterÃ­sticas el nÃºmero de habitaciones y el precio, seguramente el nÃºmero de habitaciones no serÃ¡ mucho mayor de 3 y en cambio el precio puede ser mayor incluso de 300000 \euro .\cite{coursera}

\subsection*{Tercera Fase: Algoritmo K-means}

En esta fase se implementa el algoritmo \textbf{K-means}.
\begin{enumerate}
	\item En primer lugar inicia los \textit{centroides} con el criterio establecido por el usuario, o la matriz de bits de pertenencias.
	\item Recorre las instancias del conjunto y calcula la distancia a cada uno de los \textit{codeword} actualizando la matriz de bits de pertenencia,el valor 		del bit es uno si es el centroide mÃ¡s cercano a la instancia.
	\item Se calcula de nuevo el vector promedio para cada cluster.
	\item Iterar los pasos dos y tres hasta converger.
\end{enumerate}

\subsection*{Cuarta Fase: EvaluaciÃ³n}

En esta fase se tratarÃ¡ de automatizar la evaluaciÃ³n del algoritmo frente a los datos obtenidos con distintas ejecuciones, variando los parÃ¡metros o incluso con  
los resultados obtenidos con el modelo de \textbf{K-means} que ya implementa el API de \textbf{weka}.

\subsection*{Dependencias}
 %mapa de diseÃ±o donde se muestran las dependencias y se documentan las rutinas.
\begin{figure}[h!]
	\centering
	\includegraphics[scale=0.50]{./img/dependenciasKmeans.pdf}%crear esquema para incluirlo
	\caption[Esquema de dependencias del sistema]{Dependencias del sistema}
	\label{fig:dependencias}
\end{figure}

%\footnotetext{Imagen obtenida de:
%\href{http://stackoverflow.com/questions/6160495/support-vector-machines-a-simple-explanation}{http://stackoverflow.com/questions/6160495/support-vector-machines-a-simple-explanation}.}

%\footnotetext{Imagen obtenida de:
%\href{http://en.wikipedia.org/wiki/File:Svm\_max\_sep\_hyperplane\_with\_margin.png}{\nolinkurl{http://en.wikipedia.org/wiki/File:Svm\_max\_sep\_hyperplane\_with\_margin.png}}.}

%\begin{equation}
%	min\frac{1}{2}||w||^{2}
%	\label{eq:pl}
%\end{equation}

\subsection{Algoritmo en pseudocÃ³digo}

\begin{lstlisting}
Let k be the number of clusters to partition the data set
Let X = {x_{1},x_{2}, ..., x_{n}} be the data set to be analyzed
Let M = {m_{1}, m_{2}, ..., m_{k}} be the code-book associated to the clusters
Let dist(a, b) be the desired distance metric
Let B = {B_{11}, B_{12}, ..., B_{nk}} be the temporary pertenece bit matrix

Ensure: C = {C_{1}, C_{2}, ..., C_{k}} set of clusterized instances

Begin:

	//randomly initialize the first centroids
	for each m_{j}
		m_{j} = randomsample(X)
	end
	
	//assign dataset instances to each cluster generated by the centroids
	for each x_{n}
		B_{nj} = 1 sii argmin dist (xn,mj) = mj \foreach m_{j} si no B_{nj} = 0 
	end
		
	for each B_{nj}
		if B_{nj} == 1
			C_{j}.add(x_{i}) 
		end
	end
	
	//iterate the algorithm generatin new centroids based on previously clusterized instances until there are no changes between iterations
	while changes in M do
		for each m_{j}
			m_{j}new = calculatecentroid(C_{j})
			if m_{j}new == m_{j}
				changes = false
			else
				changes = true
			end
			m_{j} = m_{j}new	
		end
		
		for each x_{n}
			B_{nj} = 1 sii argmin dist (xn,mj) = mj \foreach m_{j} si no B_{nj} = 0 
		end
		
		for each B_{nj}
			if B_{nj} == 1
				C_{j}.add(x_{i}) 
			end
		end
	end
	
	return C = {C_{1}, C_{2}, ..., C_{k}}
end
\end{lstlisting}
\section{ImplementaciÃ³n}

\subsubsection{Problemas encontrados} 

\subsubsection{Soluciones adoptadas} 

\section{ValidaciÃ³n del \textit{software}}

\subsection{DiseÃ±o del banco de pruebas}

\section{AnÃ¡lisis de resultados}

\subsection{Modificando inicializaciones}

\subsection{Modificando distancia Minkowski}

\subsection{Criterios de convergencia}

\subsubsection{NÃºmero fijo de iteraciones}

\subsubsection{Disimilitud entre \textit{codebooks}}

\subsection{Distintas mÃ©tricas}

\subsubsection{Manhattan}

\subsubsection{EuclÃ­dea}

\subsubsection{Minkowski}

\section{ClasificaciÃ³n supervisada respecto de }

%\section{Preproceso de los datos}
%
%\subsubsection{Randomize}
%
%\subsubsection{Normalize}
%
%\subsubsection{Outliers y Extreme Values}
%
%\subsubsection{Problemas al implementar el preproceso de datos}
%
%\subsection{Utils}
%
%\subsubsection{StopWatch}
%
%Esta funciÃ³n se encarga de indicarnos el tiempo transcurrido, en segundos,
%desde donde se instancia el objeto, hasta donde se para el
%contador\par
%
%Creemos necesario su uso, ya que nos aporta una visiÃ³n objetiva del coste de tiempo computacional 
%de los distintos algoritmos implementados,como por ejemplo en el proceso de
%clasificaciÃ³n de las instancias sin estimar incluidas en los distintos conjuntos de
%test.
%
%\subsubsection{VerboseCutter}
%
%Esta MAE se encarga de eliminar la salida de sistema que
%imprime al hacer la evaluaciÃ³n el clasificador \textit{LibSVM} por defecto.\par
%
%La implementaciÃ³n de esta funcionalidad ha sido posible gracias a la inestimable
%ayuda por parte de otro de los grupos\footnote{David RamÃ­rez, BegoÃ±a Carcedo,
%Andoni MartÃ­n, Marta Aguilera}.\par
%
%Eliminando la salida de sistema, podemos mostrar de forma mÃ¡s
%clara infomaciÃ³n relevante de nuestro programa, facilitando, de esta manera,
%la comprensiÃ³n de los datos por parte del usuario.AdemÃ¡s se puede seguir
%revisando dicha salida en el fichero temporal al que ha sido redireccionada.\par
%
%\paragraph{Problemas de ejecuciÃ³n:}
%	Al activar y desactivar esta MAE dentro de bucles anidados, no obtenemos el
%	resultado deseado, esto ocurre por falta de capacidad de respuesta por
%	capacidad de procesamiento y velocidad de escritura/lectura del disco.
%\paragraph{SoluciÃ³n:}
%	Aunque con desactivar la salida antes de cada evaluaciÃ³n es suficiente, hemos
%	sacado la llamada a la MAE fuera de los bucles(antes de los bucles se desactiva y despues de los bucles se activa la salida de sistema).
%	De esta manera hemos conseguido los resultados deseados.



\section{Conclusiones}

	\begin{itemize}
		\item Breve descripciÃ³n de las motivaciones para llevar a cabo tÃ©cnicas de clustering.
		\item Conclusiones a la vista de los resultados mÃ¡s relevantes.
		\item Conclusiones generales.(AnÃ¡lisis de fortalezas del sw y reflexiones sobre la tarea.
		\item AnÃ¡lisis de puntos dÃ©biles y propuestas de mejoras.
	\end{itemize}

\section{ValoraciÃ³n subjetiva}

\begin{enumerate}

	\item Â¿Has alcanzado los objetivos que se plantean? 
	
	\item Â¿Te ha resultado de utilidad la tarea planteada?

	\item Â¿QuÃ© dificultades has encontrado?Valora el grado de dificultad de la tarea.

	\item  Â¿CuÃ¡nto tiempo has trabajado en esta tarea? Desglosado:

		\begin{table}[H]
		\centering
		\resizebox{8cm}{!}{
						\begin{tabular}{|l|l|}
							\hline
							\multicolumn{2}{|c|}{\textbf{Coste temporal}}\\
							\hline
								DiseÃ±o de software & \\
								ImplementaciÃ³n de software & \\
								Tiempo trabajando con Weka & \\
								BÃºsqueda bibliogrÃ¡fica & \\
								Informe & 1\\
								\hline
							\end{tabular}
						}
		\end{table}

	\item  Sugerencias para mejorar la tarea. Sugerencias para que se consiga
	despertar mayor interÃ©s y motivaciÃ³n en los alumnos.\par

	\item  CrÃ­ticas(constructivas).

\end{enumerate} 

\newpage

\bibliographystyle{plain}
\bibliography{bibliografia}

%Ser crÃ­tico, analizar datos experemientales.Aplicar pequeÃ±os heurÃ­sticos.

\end{document} 
